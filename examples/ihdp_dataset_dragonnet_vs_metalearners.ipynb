{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHDP dataset: Dragonnet vs Meta Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:27:47.595896Z",
     "start_time": "2020-01-14T23:27:47.587276Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:27:47.884710Z",
     "start_time": "2020-01-14T23:27:47.881718Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../causalml/inference/nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:27:48.170938Z",
     "start_time": "2020-01-14T23:27:48.148542Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:27:53.788066Z",
     "start_time": "2020-01-14T23:27:53.725107Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.match import NearestNeighborMatch, MatchOptimizer, create_table_one\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from causalml.dataset import *\n",
    "from causalml.metrics import *\n",
    "\n",
    "from dragonnet import train_dragon\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:27:53.665071Z",
     "start_time": "2020-01-14T23:27:53.611927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.0\n"
     ]
    }
   ],
   "source": [
    "import causalml\n",
    "print(causalml.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: IHDP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:32:52.776995Z",
     "start_time": "2020-01-14T23:32:52.710247Z"
    }
   },
   "outputs": [],
   "source": [
    "ihdp_dir = '/Users/mike.yung/Documents/repos/dragonnet/dat/ihdp/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:32:54.131809Z",
     "start_time": "2020-01-14T23:32:54.073759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "['ihdp_npci_1.csv', 'ihdp_npci_10.csv', 'ihdp_npci_11.csv', 'ihdp_npci_12.csv', 'ihdp_npci_13.csv', 'ihdp_npci_14.csv', 'ihdp_npci_15.csv', 'ihdp_npci_16.csv', 'ihdp_npci_17.csv', 'ihdp_npci_18.csv', 'ihdp_npci_19.csv', 'ihdp_npci_2.csv', 'ihdp_npci_20.csv', 'ihdp_npci_21.csv', 'ihdp_npci_22.csv', 'ihdp_npci_23.csv', 'ihdp_npci_24.csv', 'ihdp_npci_25.csv', 'ihdp_npci_26.csv', 'ihdp_npci_27.csv', 'ihdp_npci_28.csv', 'ihdp_npci_29.csv', 'ihdp_npci_3.csv', 'ihdp_npci_30.csv', 'ihdp_npci_31.csv', 'ihdp_npci_32.csv', 'ihdp_npci_33.csv', 'ihdp_npci_34.csv', 'ihdp_npci_35.csv', 'ihdp_npci_36.csv', 'ihdp_npci_37.csv', 'ihdp_npci_38.csv', 'ihdp_npci_39.csv', 'ihdp_npci_4.csv', 'ihdp_npci_40.csv', 'ihdp_npci_41.csv', 'ihdp_npci_42.csv', 'ihdp_npci_43.csv', 'ihdp_npci_44.csv', 'ihdp_npci_45.csv', 'ihdp_npci_46.csv', 'ihdp_npci_47.csv', 'ihdp_npci_48.csv', 'ihdp_npci_49.csv', 'ihdp_npci_5.csv', 'ihdp_npci_50.csv', 'ihdp_npci_6.csv', 'ihdp_npci_7.csv', 'ihdp_npci_8.csv', 'ihdp_npci_9.csv']"
      ],
      "text/plain": [
       "['ihdp_npci_1.csv',\n",
       " 'ihdp_npci_10.csv',\n",
       " 'ihdp_npci_11.csv',\n",
       " 'ihdp_npci_12.csv',\n",
       " 'ihdp_npci_13.csv',\n",
       " 'ihdp_npci_14.csv',\n",
       " 'ihdp_npci_15.csv',\n",
       " 'ihdp_npci_16.csv',\n",
       " 'ihdp_npci_17.csv',\n",
       " 'ihdp_npci_18.csv',\n",
       " 'ihdp_npci_19.csv',\n",
       " 'ihdp_npci_2.csv',\n",
       " 'ihdp_npci_20.csv',\n",
       " 'ihdp_npci_21.csv',\n",
       " 'ihdp_npci_22.csv',\n",
       " 'ihdp_npci_23.csv',\n",
       " 'ihdp_npci_24.csv',\n",
       " 'ihdp_npci_25.csv',\n",
       " 'ihdp_npci_26.csv',\n",
       " 'ihdp_npci_27.csv',\n",
       " 'ihdp_npci_28.csv',\n",
       " 'ihdp_npci_29.csv',\n",
       " 'ihdp_npci_3.csv',\n",
       " 'ihdp_npci_30.csv',\n",
       " 'ihdp_npci_31.csv',\n",
       " 'ihdp_npci_32.csv',\n",
       " 'ihdp_npci_33.csv',\n",
       " 'ihdp_npci_34.csv',\n",
       " 'ihdp_npci_35.csv',\n",
       " 'ihdp_npci_36.csv',\n",
       " 'ihdp_npci_37.csv',\n",
       " 'ihdp_npci_38.csv',\n",
       " 'ihdp_npci_39.csv',\n",
       " 'ihdp_npci_4.csv',\n",
       " 'ihdp_npci_40.csv',\n",
       " 'ihdp_npci_41.csv',\n",
       " 'ihdp_npci_42.csv',\n",
       " 'ihdp_npci_43.csv',\n",
       " 'ihdp_npci_44.csv',\n",
       " 'ihdp_npci_45.csv',\n",
       " 'ihdp_npci_46.csv',\n",
       " 'ihdp_npci_47.csv',\n",
       " 'ihdp_npci_48.csv',\n",
       " 'ihdp_npci_49.csv',\n",
       " 'ihdp_npci_5.csv',\n",
       " 'ihdp_npci_50.csv',\n",
       " 'ihdp_npci_6.csv',\n",
       " 'ihdp_npci_7.csv',\n",
       " 'ihdp_npci_8.csv',\n",
       " 'ihdp_npci_9.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(ihdp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T01:43:12.485873Z",
     "start_time": "2020-01-14T01:43:12.415906Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{ihdp_dir}/ihdp_npci_1.csv', header=None)\n",
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ]\n",
    "\n",
    "for i in range(1,26):\n",
    "    col.append(\"x\"+str(i))\n",
    "df.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T01:43:13.134208Z",
     "start_time": "2020-01-14T01:43:13.067389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "      <td>3.268256</td>\n",
       "      <td>6.854457</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  y_factual  y_cfactual       mu0       mu1        x1        x2  \\\n",
       "0          1   5.599916    4.318780  3.268256  6.854457 -0.528603 -0.343455   \n",
       "1          0   6.875856    7.856495  6.636059  7.562718 -1.736945 -1.802002   \n",
       "2          0   2.996273    6.633952  1.570536  6.121617 -0.807451 -0.202946   \n",
       "3          0   1.366206    5.697239  1.244738  5.889125  0.390083  0.596582   \n",
       "4          0   1.963538    6.202582  1.685048  6.191994 -1.045229 -0.602710   \n",
       "\n",
       "         x3        x4        x5  ...  x16  x17  x18  x19  x20  x21  x22  x23  \\\n",
       "0  1.128554  0.161703 -0.316603  ...    1    1    1    1    0    0    0    0   \n",
       "1  0.383828  2.244320 -0.629189  ...    1    1    1    1    0    0    0    0   \n",
       "2 -0.360898 -0.879606  0.808706  ...    1    0    1    1    0    0    0    0   \n",
       "3 -1.850350 -0.879606 -0.004017  ...    1    0    1    1    0    0    0    0   \n",
       "4  0.011465  0.161703  0.683672  ...    1    1    1    1    0    0    0    0   \n",
       "\n",
       "   x24  x25  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:52:56.974649Z",
     "start_time": "2020-01-14T00:52:56.927466Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.813922\n",
       "1    0.186078\n",
       "Name: treatment, dtype: float64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df['treatment']).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:52:57.454083Z",
     "start_time": "2020-01-14T00:52:57.375888Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:,'x1':]\n",
    "treatment = df['treatment']\n",
    "y = df['y_factual']\n",
    "tau = df.apply(lambda d: d['y_factual'] - d['y_cfactual']\n",
    "               if d['treatment']==1\n",
    "               else d['y_cfactual'] - d['y_factual'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:52:59.478425Z",
     "start_time": "2020-01-14T00:52:57.892031Z"
    }
   },
   "outputs": [],
   "source": [
    "p_model = LogisticRegressionCV(penalty='elasticnet', solver='saga', l1_ratios=np.linspace(0,1,10),\n",
    "                               cv=StratifiedKFold(n_splits=2, shuffle=False))\n",
    "p_model.fit(X, treatment)\n",
    "p = p_model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:53:04.563064Z",
     "start_time": "2020-01-14T00:52:59.823767Z"
    }
   },
   "outputs": [],
   "source": [
    "s_learner = BaseSRegressor(LGBMRegressor())\n",
    "s_ate = s_learner.estimate_ate(X, treatment, y)[0]\n",
    "s_ite = s_learner.fit_predict(X, treatment, y)\n",
    "\n",
    "t_learner = BaseTRegressor(LGBMRegressor())\n",
    "t_ate = t_learner.estimate_ate(X, treatment, y)[0][0]\n",
    "t_ite = t_learner.fit_predict(X, treatment, y)\n",
    "\n",
    "x_learner = BaseXRegressor(LGBMRegressor())\n",
    "x_ate = x_learner.estimate_ate(X, p, treatment, y)[0][0]\n",
    "x_ite = x_learner.fit_predict(X, p, treatment, y)\n",
    "\n",
    "r_learner = BaseRRegressor(LGBMRegressor())\n",
    "r_ate = r_learner.estimate_ate(X, p, treatment, y)[0][0]\n",
    "r_ite = r_learner.fit_predict(X, p, treatment, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:04.801216Z",
     "start_time": "2020-01-14T00:56:57.628657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here making dragonnet\n",
      "Train on 597 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2841.0125 - regression_loss: 1321.2487 - binary_classification_loss: 40.0279 - treatment_accuracy: 0.7780 - track_epsilon: 0.0148 - val_loss: 2121.3647 - val_regression_loss: 827.0235 - val_binary_classification_loss: 33.0737 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0195\n",
      "Epoch 2/100\n",
      "597/597 [==============================] - 0s 61us/step - loss: 763.6118 - regression_loss: 338.6924 - binary_classification_loss: 32.3364 - treatment_accuracy: 0.8593 - track_epsilon: 0.0209 - val_loss: 347.3359 - val_regression_loss: 128.6071 - val_binary_classification_loss: 33.6181 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0205\n",
      "Epoch 3/100\n",
      "597/597 [==============================] - 0s 78us/step - loss: 301.3724 - regression_loss: 130.7361 - binary_classification_loss: 27.8279 - treatment_accuracy: 0.8433 - track_epsilon: 0.0196 - val_loss: 248.5953 - val_regression_loss: 85.4087 - val_binary_classification_loss: 36.8088 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0197\n",
      "Epoch 4/100\n",
      "597/597 [==============================] - 0s 82us/step - loss: 240.2806 - regression_loss: 101.7680 - binary_classification_loss: 27.0564 - treatment_accuracy: 0.8497 - track_epsilon: 0.0210 - val_loss: 298.6708 - val_regression_loss: 102.8289 - val_binary_classification_loss: 38.9177 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0223\n",
      "Epoch 5/100\n",
      "597/597 [==============================] - 0s 84us/step - loss: 222.5570 - regression_loss: 92.6581 - binary_classification_loss: 26.7763 - treatment_accuracy: 0.8433 - track_epsilon: 0.0219 - val_loss: 233.3183 - val_regression_loss: 75.1365 - val_binary_classification_loss: 38.1514 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0211\n",
      "Epoch 6/100\n",
      "597/597 [==============================] - 0s 81us/step - loss: 205.3014 - regression_loss: 83.4134 - binary_classification_loss: 26.7462 - treatment_accuracy: 0.8593 - track_epsilon: 0.0207 - val_loss: 237.1411 - val_regression_loss: 79.1722 - val_binary_classification_loss: 38.8747 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0203\n",
      "Epoch 7/100\n",
      "597/597 [==============================] - 0s 92us/step - loss: 200.5395 - regression_loss: 79.9572 - binary_classification_loss: 26.7048 - treatment_accuracy: 0.8593 - track_epsilon: 0.0203 - val_loss: 225.1437 - val_regression_loss: 72.9726 - val_binary_classification_loss: 38.2648 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0202\n",
      "Epoch 8/100\n",
      "597/597 [==============================] - 0s 85us/step - loss: 191.9312 - regression_loss: 76.4619 - binary_classification_loss: 26.6163 - treatment_accuracy: 0.8497 - track_epsilon: 0.0201 - val_loss: 226.3857 - val_regression_loss: 74.3430 - val_binary_classification_loss: 38.1828 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0198\n",
      "Epoch 9/100\n",
      "597/597 [==============================] - 0s 81us/step - loss: 184.7939 - regression_loss: 74.2657 - binary_classification_loss: 26.4996 - treatment_accuracy: 0.8497 - track_epsilon: 0.0196 - val_loss: 233.8469 - val_regression_loss: 78.5708 - val_binary_classification_loss: 38.3290 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0194\n",
      "Train on 597 samples, validate on 150 samples\n",
      "Epoch 1/300\n",
      "597/597 [==============================] - 0s 787us/step - loss: 183.0824 - regression_loss: 72.2700 - binary_classification_loss: 26.3939 - treatment_accuracy: 0.8561 - track_epsilon: 0.0186 - val_loss: 219.8046 - val_regression_loss: 71.6722 - val_binary_classification_loss: 37.7342 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0190\n",
      "Epoch 2/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 177.6443 - regression_loss: 71.7012 - binary_classification_loss: 26.4170 - treatment_accuracy: 0.8593 - track_epsilon: 0.0168 - val_loss: 224.0777 - val_regression_loss: 74.2247 - val_binary_classification_loss: 37.7539 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0140\n",
      "Epoch 3/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 179.4991 - regression_loss: 71.0637 - binary_classification_loss: 26.3751 - treatment_accuracy: 0.8593 - track_epsilon: 0.0125 - val_loss: 221.7434 - val_regression_loss: 73.7050 - val_binary_classification_loss: 37.6605 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0097\n",
      "Epoch 4/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 177.6250 - regression_loss: 69.7280 - binary_classification_loss: 26.2790 - treatment_accuracy: 0.8593 - track_epsilon: 0.0069 - val_loss: 214.3596 - val_regression_loss: 70.9907 - val_binary_classification_loss: 37.4933 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0057\n",
      "Epoch 5/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 173.5994 - regression_loss: 68.8227 - binary_classification_loss: 26.2270 - treatment_accuracy: 0.8497 - track_epsilon: 0.0080 - val_loss: 215.8967 - val_regression_loss: 71.5591 - val_binary_classification_loss: 37.4991 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0064\n",
      "Epoch 6/300\n",
      "597/597 [==============================] - 0s 58us/step - loss: 173.2425 - regression_loss: 68.0619 - binary_classification_loss: 26.2037 - treatment_accuracy: 0.8433 - track_epsilon: 0.0061 - val_loss: 221.0200 - val_regression_loss: 74.3148 - val_binary_classification_loss: 37.6711 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0056\n",
      "Epoch 7/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 169.1356 - regression_loss: 67.7256 - binary_classification_loss: 26.1221 - treatment_accuracy: 0.8465 - track_epsilon: 0.0045 - val_loss: 212.7291 - val_regression_loss: 70.2352 - val_binary_classification_loss: 37.3339 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0082\n",
      "Epoch 8/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 170.0730 - regression_loss: 66.9490 - binary_classification_loss: 26.0694 - treatment_accuracy: 0.8561 - track_epsilon: 0.0108 - val_loss: 214.3529 - val_regression_loss: 71.2038 - val_binary_classification_loss: 37.5733 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0087\n",
      "Epoch 9/300\n",
      "597/597 [==============================] - 0s 58us/step - loss: 168.6664 - regression_loss: 66.3296 - binary_classification_loss: 26.0118 - treatment_accuracy: 0.8593 - track_epsilon: 0.0082 - val_loss: 207.9508 - val_regression_loss: 68.2667 - val_binary_classification_loss: 37.4999 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0091\n",
      "Epoch 10/300\n",
      "597/597 [==============================] - 0s 62us/step - loss: 167.0585 - regression_loss: 65.9684 - binary_classification_loss: 25.9941 - treatment_accuracy: 0.8465 - track_epsilon: 0.0100 - val_loss: 228.6376 - val_regression_loss: 77.4860 - val_binary_classification_loss: 37.8848 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0129\n",
      "Epoch 11/300\n",
      "597/597 [==============================] - 0s 61us/step - loss: 168.3652 - regression_loss: 66.6246 - binary_classification_loss: 25.9611 - treatment_accuracy: 0.8497 - track_epsilon: 0.0102 - val_loss: 218.7033 - val_regression_loss: 73.0964 - val_binary_classification_loss: 37.6717 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0124\n",
      "Epoch 12/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 166.0733 - regression_loss: 65.1970 - binary_classification_loss: 25.9255 - treatment_accuracy: 0.8497 - track_epsilon: 0.0120 - val_loss: 214.9122 - val_regression_loss: 71.5041 - val_binary_classification_loss: 37.8062 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0105\n",
      "Epoch 13/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 165.4006 - regression_loss: 64.4239 - binary_classification_loss: 25.8735 - treatment_accuracy: 0.8529 - track_epsilon: 0.0092 - val_loss: 205.9650 - val_regression_loss: 67.2290 - val_binary_classification_loss: 37.6580 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0113\n",
      "Epoch 14/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 165.6005 - regression_loss: 64.5776 - binary_classification_loss: 25.8447 - treatment_accuracy: 0.8593 - track_epsilon: 0.0119 - val_loss: 212.6695 - val_regression_loss: 70.4235 - val_binary_classification_loss: 37.9211 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0114\n",
      "Epoch 15/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 162.0677 - regression_loss: 63.8626 - binary_classification_loss: 25.8006 - treatment_accuracy: 0.8561 - track_epsilon: 0.0108 - val_loss: 203.3294 - val_regression_loss: 65.9407 - val_binary_classification_loss: 37.6138 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0117\n",
      "Epoch 16/300\n",
      "597/597 [==============================] - 0s 59us/step - loss: 162.9898 - regression_loss: 63.8541 - binary_classification_loss: 25.7173 - treatment_accuracy: 0.8465 - track_epsilon: 0.0095 - val_loss: 204.6454 - val_regression_loss: 66.9173 - val_binary_classification_loss: 37.6978 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0110\n",
      "Epoch 17/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 160.6748 - regression_loss: 63.5812 - binary_classification_loss: 25.7066 - treatment_accuracy: 0.8561 - track_epsilon: 0.0091 - val_loss: 204.3292 - val_regression_loss: 66.5225 - val_binary_classification_loss: 37.5395 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0118\n",
      "Epoch 18/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 164.4754 - regression_loss: 64.0790 - binary_classification_loss: 25.6810 - treatment_accuracy: 0.8561 - track_epsilon: 0.0121 - val_loss: 200.5690 - val_regression_loss: 64.9108 - val_binary_classification_loss: 37.4876 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0110\n",
      "Epoch 19/300\n",
      "597/597 [==============================] - 0s 58us/step - loss: 163.7831 - regression_loss: 63.7298 - binary_classification_loss: 25.6380 - treatment_accuracy: 0.8529 - track_epsilon: 0.0098 - val_loss: 212.4710 - val_regression_loss: 70.7182 - val_binary_classification_loss: 38.0225 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0102\n",
      "Epoch 20/300\n",
      "597/597 [==============================] - 0s 58us/step - loss: 160.6079 - regression_loss: 62.8226 - binary_classification_loss: 25.6486 - treatment_accuracy: 0.8593 - track_epsilon: 0.0094 - val_loss: 200.9255 - val_regression_loss: 65.4228 - val_binary_classification_loss: 37.6935 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0093\n",
      "Epoch 21/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 159.6602 - regression_loss: 61.9753 - binary_classification_loss: 25.6037 - treatment_accuracy: 0.8433 - track_epsilon: 0.0092 - val_loss: 209.8991 - val_regression_loss: 69.7425 - val_binary_classification_loss: 37.9038 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0086\n",
      "Epoch 22/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 160.5525 - regression_loss: 62.4430 - binary_classification_loss: 25.5929 - treatment_accuracy: 0.8529 - track_epsilon: 0.0072 - val_loss: 200.5901 - val_regression_loss: 65.3240 - val_binary_classification_loss: 37.5678 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0089\n",
      "Epoch 23/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 157.6728 - regression_loss: 61.8657 - binary_classification_loss: 25.5349 - treatment_accuracy: 0.8529 - track_epsilon: 0.0096 - val_loss: 198.7237 - val_regression_loss: 64.2659 - val_binary_classification_loss: 37.4959 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0096\n",
      "Epoch 24/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 158.7225 - regression_loss: 62.2151 - binary_classification_loss: 25.5000 - treatment_accuracy: 0.8561 - track_epsilon: 0.0057 - val_loss: 203.8328 - val_regression_loss: 66.9891 - val_binary_classification_loss: 37.6759 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0088\n",
      "Epoch 25/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 157.3014 - regression_loss: 61.7475 - binary_classification_loss: 25.4592 - treatment_accuracy: 0.8593 - track_epsilon: 0.0095 - val_loss: 202.6470 - val_regression_loss: 66.3965 - val_binary_classification_loss: 37.6004 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0090\n",
      "Epoch 26/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 158.2724 - regression_loss: 62.0716 - binary_classification_loss: 25.4619 - treatment_accuracy: 0.8593 - track_epsilon: 0.0087 - val_loss: 199.9374 - val_regression_loss: 65.5875 - val_binary_classification_loss: 37.6352 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0054\n",
      "Epoch 27/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 158.1167 - regression_loss: 61.1759 - binary_classification_loss: 25.4552 - treatment_accuracy: 0.8625 - track_epsilon: 0.0035 - val_loss: 196.5988 - val_regression_loss: 63.8266 - val_binary_classification_loss: 37.3722 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0073\n",
      "Epoch 28/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 158.5166 - regression_loss: 61.2371 - binary_classification_loss: 25.4076 - treatment_accuracy: 0.8529 - track_epsilon: 0.0081 - val_loss: 198.2746 - val_regression_loss: 64.6080 - val_binary_classification_loss: 37.4046 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0073\n",
      "Epoch 29/300\n",
      "597/597 [==============================] - 0s 67us/step - loss: 154.5647 - regression_loss: 60.5583 - binary_classification_loss: 25.4035 - treatment_accuracy: 0.8433 - track_epsilon: 0.0069 - val_loss: 197.6992 - val_regression_loss: 64.6205 - val_binary_classification_loss: 37.5647 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0049\n",
      "Epoch 30/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 156.7964 - regression_loss: 60.3301 - binary_classification_loss: 25.3599 - treatment_accuracy: 0.8529 - track_epsilon: 0.0060 - val_loss: 193.9008 - val_regression_loss: 62.9502 - val_binary_classification_loss: 37.3830 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0047\n",
      "Epoch 31/300\n",
      "597/597 [==============================] - 0s 60us/step - loss: 155.5526 - regression_loss: 60.5224 - binary_classification_loss: 25.3489 - treatment_accuracy: 0.8593 - track_epsilon: 0.0027 - val_loss: 198.6279 - val_regression_loss: 65.1818 - val_binary_classification_loss: 37.3666 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0055\n",
      "Epoch 32/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 156.2392 - regression_loss: 60.4200 - binary_classification_loss: 25.3324 - treatment_accuracy: 0.8497 - track_epsilon: 0.0068 - val_loss: 195.1864 - val_regression_loss: 63.1936 - val_binary_classification_loss: 37.2134 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0073\n",
      "Epoch 33/300\n",
      "597/597 [==============================] - 0s 57us/step - loss: 155.6066 - regression_loss: 60.5331 - binary_classification_loss: 25.2872 - treatment_accuracy: 0.8529 - track_epsilon: 0.0050 - val_loss: 192.3857 - val_regression_loss: 62.4233 - val_binary_classification_loss: 37.3079 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0041\n",
      "Epoch 34/300\n",
      "597/597 [==============================] - 0s 58us/step - loss: 154.2413 - regression_loss: 60.2714 - binary_classification_loss: 25.2709 - treatment_accuracy: 0.8497 - track_epsilon: 0.0058 - val_loss: 195.5962 - val_regression_loss: 63.7694 - val_binary_classification_loss: 37.2434 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0050\n",
      "Epoch 35/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 155.1120 - regression_loss: 60.4026 - binary_classification_loss: 25.2441 - treatment_accuracy: 0.8625 - track_epsilon: 0.0033 - val_loss: 207.6084 - val_regression_loss: 69.8074 - val_binary_classification_loss: 37.4009 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0034\n",
      "Epoch 36/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 154.3696 - regression_loss: 59.8357 - binary_classification_loss: 25.2468 - treatment_accuracy: 0.8529 - track_epsilon: 0.0041 - val_loss: 202.4497 - val_regression_loss: 67.0202 - val_binary_classification_loss: 37.3219 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/300\n",
      "597/597 [==============================] - 0s 49us/step - loss: 154.6685 - regression_loss: 60.3431 - binary_classification_loss: 25.2238 - treatment_accuracy: 0.8433 - track_epsilon: 0.0054 - val_loss: 189.8671 - val_regression_loss: 61.3494 - val_binary_classification_loss: 36.9981 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0025\n",
      "Epoch 38/300\n",
      "597/597 [==============================] - 0s 49us/step - loss: 155.2768 - regression_loss: 60.3209 - binary_classification_loss: 25.2121 - treatment_accuracy: 0.8433 - track_epsilon: 0.0014 - val_loss: 196.2463 - val_regression_loss: 64.2867 - val_binary_classification_loss: 37.2283 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0039\n",
      "Epoch 39/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 153.5994 - regression_loss: 59.8586 - binary_classification_loss: 25.1677 - treatment_accuracy: 0.8593 - track_epsilon: 0.0045 - val_loss: 193.8690 - val_regression_loss: 63.0034 - val_binary_classification_loss: 36.9175 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0052\n",
      "Epoch 40/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 154.2670 - regression_loss: 60.4183 - binary_classification_loss: 25.1286 - treatment_accuracy: 0.8529 - track_epsilon: 0.0036 - val_loss: 195.4605 - val_regression_loss: 64.0603 - val_binary_classification_loss: 37.0602 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0028\n",
      "Epoch 41/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 152.6495 - regression_loss: 59.4777 - binary_classification_loss: 25.1831 - treatment_accuracy: 0.8465 - track_epsilon: 0.0036 - val_loss: 194.0748 - val_regression_loss: 63.4079 - val_binary_classification_loss: 37.0790 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0025\n",
      "Epoch 42/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 153.0167 - regression_loss: 59.4505 - binary_classification_loss: 25.1411 - treatment_accuracy: 0.8465 - track_epsilon: 0.0021 - val_loss: 190.3944 - val_regression_loss: 61.5346 - val_binary_classification_loss: 36.9179 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0028\n",
      "Epoch 43/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 155.1328 - regression_loss: 59.5397 - binary_classification_loss: 25.1105 - treatment_accuracy: 0.8561 - track_epsilon: 0.0049 - val_loss: 209.0002 - val_regression_loss: 70.3540 - val_binary_classification_loss: 37.1376 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0037\n",
      "Epoch 44/300\n",
      "597/597 [==============================] - 0s 55us/step - loss: 153.0094 - regression_loss: 59.5459 - binary_classification_loss: 25.1001 - treatment_accuracy: 0.8465 - track_epsilon: 0.0016 - val_loss: 189.3740 - val_regression_loss: 61.3981 - val_binary_classification_loss: 36.8855 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 8.0178e-04\n",
      "Epoch 45/300\n",
      "597/597 [==============================] - ETA: 0s - loss: 187.5349 - regression_loss: 79.5090 - binary_classification_loss: 26.0302 - treatment_accuracy: 0.8594 - track_epsilon: 8.0178e-0 - 0s 51us/step - loss: 153.5101 - regression_loss: 59.1064 - binary_classification_loss: 25.0948 - treatment_accuracy: 0.8561 - track_epsilon: 0.0017 - val_loss: 192.3085 - val_regression_loss: 62.7112 - val_binary_classification_loss: 36.8654 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0022\n",
      "Epoch 46/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 152.3799 - regression_loss: 58.7939 - binary_classification_loss: 25.0858 - treatment_accuracy: 0.8561 - track_epsilon: 0.0029 - val_loss: 195.0827 - val_regression_loss: 64.1021 - val_binary_classification_loss: 36.9104 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0018\n",
      "Epoch 47/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 152.6944 - regression_loss: 58.7734 - binary_classification_loss: 25.0626 - treatment_accuracy: 0.8593 - track_epsilon: 0.0015 - val_loss: 194.2264 - val_regression_loss: 63.7345 - val_binary_classification_loss: 36.8310 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0014\n",
      "Epoch 48/300\n",
      "597/597 [==============================] - 0s 56us/step - loss: 152.9874 - regression_loss: 58.5737 - binary_classification_loss: 25.0430 - treatment_accuracy: 0.8593 - track_epsilon: 0.0032 - val_loss: 198.8537 - val_regression_loss: 65.7943 - val_binary_classification_loss: 36.7445 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0034\n",
      "Epoch 49/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 151.7039 - regression_loss: 58.5198 - binary_classification_loss: 25.0374 - treatment_accuracy: 0.8625 - track_epsilon: 0.0017 - val_loss: 194.2514 - val_regression_loss: 63.9427 - val_binary_classification_loss: 36.8019 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 6.0075e-04\n",
      "Epoch 50/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 152.7773 - regression_loss: 59.0801 - binary_classification_loss: 25.0005 - treatment_accuracy: 0.8529 - track_epsilon: 0.0014 - val_loss: 207.9988 - val_regression_loss: 69.9908 - val_binary_classification_loss: 36.9821 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0031\n",
      "Epoch 51/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 152.6683 - regression_loss: 58.7579 - binary_classification_loss: 24.9974 - treatment_accuracy: 0.8561 - track_epsilon: 0.0031 - val_loss: 192.3191 - val_regression_loss: 62.5510 - val_binary_classification_loss: 36.6194 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0034\n",
      "Epoch 52/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 152.0677 - regression_loss: 58.6531 - binary_classification_loss: 24.9903 - treatment_accuracy: 0.8529 - track_epsilon: 0.0028 - val_loss: 191.4362 - val_regression_loss: 62.4302 - val_binary_classification_loss: 36.7157 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 9.8557e-05\n",
      "Epoch 53/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 151.9989 - regression_loss: 58.8118 - binary_classification_loss: 24.9822 - treatment_accuracy: 0.8561 - track_epsilon: 0.0015 - val_loss: 196.9012 - val_regression_loss: 65.0907 - val_binary_classification_loss: 36.6728 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 8.0562e-04\n",
      "Epoch 54/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 148.8657 - regression_loss: 58.1623 - binary_classification_loss: 24.9512 - treatment_accuracy: 0.8593 - track_epsilon: 0.0028 - val_loss: 205.6043 - val_regression_loss: 69.2986 - val_binary_classification_loss: 36.8035 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 1.2747e-04\n",
      "Epoch 55/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 150.3806 - regression_loss: 58.3015 - binary_classification_loss: 24.9545 - treatment_accuracy: 0.8465 - track_epsilon: 0.0021 - val_loss: 194.6445 - val_regression_loss: 64.1181 - val_binary_classification_loss: 36.6380 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 4.4073e-05\n",
      "Epoch 56/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 150.9734 - regression_loss: 58.4183 - binary_classification_loss: 24.9422 - treatment_accuracy: 0.8529 - track_epsilon: 0.0013 - val_loss: 189.7961 - val_regression_loss: 61.6984 - val_binary_classification_loss: 36.5556 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 3.3853e-04\n",
      "Epoch 57/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 149.6643 - regression_loss: 58.2852 - binary_classification_loss: 24.9374 - treatment_accuracy: 0.8465 - track_epsilon: 7.6962e-04 - val_loss: 193.7985 - val_regression_loss: 63.6428 - val_binary_classification_loss: 36.7258 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 5.4696e-04\n",
      "Epoch 58/300\n",
      "597/597 [==============================] - 0s 54us/step - loss: 149.7513 - regression_loss: 57.8034 - binary_classification_loss: 24.9129 - treatment_accuracy: 0.8529 - track_epsilon: 7.6901e-04 - val_loss: 199.6719 - val_regression_loss: 66.0619 - val_binary_classification_loss: 36.7023 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0025\n",
      "Epoch 59/300\n",
      "597/597 [==============================] - 0s 57us/step - loss: 152.0782 - regression_loss: 58.3155 - binary_classification_loss: 24.9118 - treatment_accuracy: 0.8561 - track_epsilon: 0.0021 - val_loss: 193.9900 - val_regression_loss: 63.6028 - val_binary_classification_loss: 36.6153 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0011\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 60/300\n",
      "597/597 [==============================] - 0s 49us/step - loss: 148.8016 - regression_loss: 57.4901 - binary_classification_loss: 24.8901 - treatment_accuracy: 0.8497 - track_epsilon: 6.4397e-04 - val_loss: 193.3938 - val_regression_loss: 63.5938 - val_binary_classification_loss: 36.5602 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 6.4959e-04\n",
      "Epoch 61/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 149.4898 - regression_loss: 57.4864 - binary_classification_loss: 24.8900 - treatment_accuracy: 0.8529 - track_epsilon: 0.0014 - val_loss: 198.6396 - val_regression_loss: 66.0363 - val_binary_classification_loss: 36.6353 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 8.2318e-04\n",
      "Epoch 62/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 149.1789 - regression_loss: 57.4577 - binary_classification_loss: 24.8833 - treatment_accuracy: 0.8561 - track_epsilon: 0.0010 - val_loss: 202.0008 - val_regression_loss: 67.5484 - val_binary_classification_loss: 36.6292 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 2.2070e-04\n",
      "Epoch 63/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 149.7736 - regression_loss: 57.2668 - binary_classification_loss: 24.8817 - treatment_accuracy: 0.8561 - track_epsilon: 5.8260e-04 - val_loss: 193.6224 - val_regression_loss: 63.5932 - val_binary_classification_loss: 36.5098 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 3.7776e-04\n",
      "Epoch 64/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 148.1201 - regression_loss: 57.1288 - binary_classification_loss: 24.8840 - treatment_accuracy: 0.8401 - track_epsilon: 4.2208e-04 - val_loss: 202.9066 - val_regression_loss: 67.9219 - val_binary_classification_loss: 36.6849 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 6.1774e-05\n",
      "Epoch 65/300\n",
      "597/597 [==============================] - 0s 49us/step - loss: 150.8036 - regression_loss: 57.7479 - binary_classification_loss: 24.8628 - treatment_accuracy: 0.8529 - track_epsilon: 0.0017 - val_loss: 195.2668 - val_regression_loss: 64.4548 - val_binary_classification_loss: 36.6026 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0012\n",
      "Epoch 66/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 148.1221 - regression_loss: 57.0035 - binary_classification_loss: 24.8576 - treatment_accuracy: 0.8593 - track_epsilon: 5.9173e-04 - val_loss: 191.2948 - val_regression_loss: 62.3294 - val_binary_classification_loss: 36.4883 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 5.8286e-04\n",
      "Epoch 67/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 151.9348 - regression_loss: 58.3368 - binary_classification_loss: 24.8522 - treatment_accuracy: 0.8625 - track_epsilon: 7.6255e-04 - val_loss: 189.4182 - val_regression_loss: 61.6456 - val_binary_classification_loss: 36.4774 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0024\n",
      "Epoch 68/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 149.7037 - regression_loss: 58.0303 - binary_classification_loss: 24.8596 - treatment_accuracy: 0.8497 - track_epsilon: 0.0018 - val_loss: 191.6241 - val_regression_loss: 62.7361 - val_binary_classification_loss: 36.4741 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0016\n",
      "Epoch 69/300\n",
      "597/597 [==============================] - 0s 49us/step - loss: 150.6507 - regression_loss: 57.5409 - binary_classification_loss: 24.8593 - treatment_accuracy: 0.8497 - track_epsilon: 0.0016 - val_loss: 196.8604 - val_regression_loss: 65.1664 - val_binary_classification_loss: 36.5688 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 3.1977e-04\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 70/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 147.2621 - regression_loss: 56.7581 - binary_classification_loss: 24.8370 - treatment_accuracy: 0.8561 - track_epsilon: 1.7361e-04 - val_loss: 194.8901 - val_regression_loss: 64.1486 - val_binary_classification_loss: 36.5160 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 3.7031e-05\n",
      "Epoch 71/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 147.1402 - regression_loss: 56.7570 - binary_classification_loss: 24.8349 - treatment_accuracy: 0.8529 - track_epsilon: 3.1024e-04 - val_loss: 194.0566 - val_regression_loss: 63.7822 - val_binary_classification_loss: 36.4997 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 6.4441e-04\n",
      "Epoch 72/300\n",
      "597/597 [==============================] - 0s 47us/step - loss: 147.1467 - regression_loss: 56.7784 - binary_classification_loss: 24.8369 - treatment_accuracy: 0.8497 - track_epsilon: 0.0014 - val_loss: 196.5925 - val_regression_loss: 65.0466 - val_binary_classification_loss: 36.5428 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0012\n",
      "Epoch 73/300\n",
      "597/597 [==============================] - 0s 46us/step - loss: 148.1310 - regression_loss: 57.1908 - binary_classification_loss: 24.8351 - treatment_accuracy: 0.8529 - track_epsilon: 0.0012 - val_loss: 193.6700 - val_regression_loss: 63.6561 - val_binary_classification_loss: 36.4763 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 9.8126e-04\n",
      "Epoch 74/300\n",
      "597/597 [==============================] - 0s 52us/step - loss: 146.1796 - regression_loss: 56.9555 - binary_classification_loss: 24.8269 - treatment_accuracy: 0.8433 - track_epsilon: 0.0012 - val_loss: 195.9729 - val_regression_loss: 64.8136 - val_binary_classification_loss: 36.5137 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0012\n",
      "Epoch 75/300\n",
      "597/597 [==============================] - 0s 47us/step - loss: 148.0188 - regression_loss: 56.8377 - binary_classification_loss: 24.8275 - treatment_accuracy: 0.8529 - track_epsilon: 0.0014 - val_loss: 194.7840 - val_regression_loss: 64.1984 - val_binary_classification_loss: 36.4985 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0011\n",
      "Epoch 76/300\n",
      "597/597 [==============================] - 0s 48us/step - loss: 146.1382 - regression_loss: 56.7954 - binary_classification_loss: 24.8235 - treatment_accuracy: 0.8465 - track_epsilon: 4.5476e-04 - val_loss: 195.9168 - val_regression_loss: 64.6574 - val_binary_classification_loss: 36.4958 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 6.2048e-04\n",
      "Epoch 77/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 146.9040 - regression_loss: 56.5974 - binary_classification_loss: 24.8246 - treatment_accuracy: 0.8529 - track_epsilon: 7.5867e-04 - val_loss: 199.1731 - val_regression_loss: 66.2606 - val_binary_classification_loss: 36.5430 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 9.9671e-04\n",
      "Epoch 78/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 149.2343 - regression_loss: 57.3261 - binary_classification_loss: 24.8190 - treatment_accuracy: 0.8561 - track_epsilon: 0.0016 - val_loss: 195.7190 - val_regression_loss: 64.8287 - val_binary_classification_loss: 36.5022 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0020\n",
      "Epoch 79/300\n",
      "597/597 [==============================] - 0s 50us/step - loss: 148.7249 - regression_loss: 57.3360 - binary_classification_loss: 24.8123 - treatment_accuracy: 0.8561 - track_epsilon: 0.0020 - val_loss: 190.4883 - val_regression_loss: 62.3234 - val_binary_classification_loss: 36.4364 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0028\n",
      "Epoch 80/300\n",
      "597/597 [==============================] - 0s 47us/step - loss: 149.1401 - regression_loss: 57.0198 - binary_classification_loss: 24.8118 - treatment_accuracy: 0.8561 - track_epsilon: 0.0026 - val_loss: 197.6369 - val_regression_loss: 65.6602 - val_binary_classification_loss: 36.5078 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0016\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 0s 47us/step - loss: 148.1820 - regression_loss: 56.9892 - binary_classification_loss: 24.8085 - treatment_accuracy: 0.8561 - track_epsilon: 0.0013 - val_loss: 193.7387 - val_regression_loss: 63.7617 - val_binary_classification_loss: 36.4481 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0013\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 82/300\n",
      "597/597 [==============================] - 0s 48us/step - loss: 147.5900 - regression_loss: 56.6485 - binary_classification_loss: 24.8080 - treatment_accuracy: 0.8497 - track_epsilon: 0.0014 - val_loss: 192.8546 - val_regression_loss: 63.3035 - val_binary_classification_loss: 36.4506 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0014\n",
      "Epoch 83/300\n",
      "597/597 [==============================] - 0s 51us/step - loss: 146.3882 - regression_loss: 56.5048 - binary_classification_loss: 24.8048 - treatment_accuracy: 0.8465 - track_epsilon: 0.0013 - val_loss: 195.8740 - val_regression_loss: 64.7386 - val_binary_classification_loss: 36.4962 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0012\n",
      "Epoch 84/300\n",
      "597/597 [==============================] - 0s 53us/step - loss: 147.2137 - regression_loss: 56.5782 - binary_classification_loss: 24.8043 - treatment_accuracy: 0.8529 - track_epsilon: 0.0013 - val_loss: 194.1760 - val_regression_loss: 63.9640 - val_binary_classification_loss: 36.4798 - val_treatment_accuracy: 0.7244 - val_track_epsilon: 0.0016\n"
     ]
    }
   ],
   "source": [
    "dragonnet = train_dragon(treatment.values.reshape(-1,1),\n",
    "                                      y.values.reshape(-1,1),\n",
    "                                      X.values,\n",
    "                                      dragon='dragonnet',\n",
    "                                      targeted_regularization=True,\n",
    "                                      val_split=0.2, neurons_per_layer=100, batch_size=64, epochs=100,\n",
    "                                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:11.803668Z",
     "start_time": "2020-01-14T00:57:11.636607Z"
    }
   },
   "outputs": [],
   "source": [
    "dragonnet_preds = dragonnet.predict(X.values)\n",
    "dragonnet_ite = (dragonnet_preds[:,1] - dragonnet_preds[:,0]).reshape(-1,1)\n",
    "dragonnet_ate = dragonnet_ite.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:12.239592Z",
     "start_time": "2020-01-14T00:57:12.193384Z"
    }
   },
   "outputs": [],
   "source": [
    "mae = lambda true,pred: np.mean(np.abs(true - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:12.744173Z",
     "start_time": "2020-01-14T00:57:12.627142Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame([s_ite.ravel(),\n",
    "                          t_ite.ravel(),\n",
    "                          x_ite.ravel(),\n",
    "                          r_ite.ravel(),\n",
    "                          dragonnet_ite.ravel(),\n",
    "                          tau.ravel(),\n",
    "                          treatment.ravel(),\n",
    "                          y.ravel()],\n",
    "                       index=['S','T','X','R','dragonnet','tau','w','y']).T\n",
    "\n",
    "df_cumgain = get_cumgain(df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:59:31.347971Z",
     "start_time": "2020-01-14T00:59:31.245984Z"
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([s_ate, t_ate, x_ate, r_ate, dragonnet_ate, tau.mean()],\n",
    "                     index=['S','T','X','R','dragonnet','actual'], columns=['ATE'])\n",
    "df_result['MAE'] = [mae(t,p) for t,p in zip([s_ite, t_ite, x_ite, r_ite, dragonnet_ite],\n",
    "                                         [tau.values.reshape(-1,1)]*5 )\n",
    "                ] + [None]\n",
    "df_result['AUUC'] = auuc_score(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:15:35.633045Z",
     "start_time": "2020-01-15T00:05:39.127471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ihdp_npci_1.csv\n",
      "Done with ihdp_npci_10.csv\n",
      "Done with ihdp_npci_11.csv\n",
      "Done with ihdp_npci_12.csv\n",
      "Batch 6: Invalid loss, terminating training\n",
      "Done with ihdp_npci_13.csv\n",
      "Done with ihdp_npci_14.csv\n",
      "Done with ihdp_npci_15.csv\n",
      "Done with ihdp_npci_16.csv\n",
      "Done with ihdp_npci_17.csv\n",
      "Done with ihdp_npci_18.csv\n",
      "Done with ihdp_npci_19.csv\n",
      "Done with ihdp_npci_2.csv\n",
      "Done with ihdp_npci_20.csv\n",
      "Batch 0: Invalid loss, terminating training\n",
      "Done with ihdp_npci_21.csv\n",
      "Done with ihdp_npci_22.csv\n",
      "Done with ihdp_npci_23.csv\n",
      "Done with ihdp_npci_24.csv\n",
      "Done with ihdp_npci_25.csv\n",
      "Batch 9: Invalid loss, terminating training\n",
      "Batch 0: Invalid loss, terminating training\n",
      "Done with ihdp_npci_26.csv\n",
      "Done with ihdp_npci_27.csv\n",
      "Batch 6: Invalid loss, terminating training\n",
      "Done with ihdp_npci_28.csv\n",
      "Done with ihdp_npci_29.csv\n",
      "Done with ihdp_npci_3.csv\n",
      "Done with ihdp_npci_30.csv\n",
      "Done with ihdp_npci_31.csv\n",
      "Done with ihdp_npci_32.csv\n",
      "Done with ihdp_npci_33.csv\n",
      "Batch 6: Invalid loss, terminating training\n",
      "Done with ihdp_npci_34.csv\n",
      "Done with ihdp_npci_35.csv\n",
      "Done with ihdp_npci_36.csv\n",
      "Batch 1: Invalid loss, terminating training\n",
      "Done with ihdp_npci_37.csv\n",
      "Done with ihdp_npci_38.csv\n",
      "Done with ihdp_npci_39.csv\n",
      "Done with ihdp_npci_4.csv\n",
      "Done with ihdp_npci_40.csv\n",
      "Done with ihdp_npci_41.csv\n",
      "Done with ihdp_npci_42.csv\n",
      "Done with ihdp_npci_43.csv\n",
      "Done with ihdp_npci_44.csv\n",
      "Done with ihdp_npci_45.csv\n",
      "Done with ihdp_npci_46.csv\n",
      "Done with ihdp_npci_47.csv\n",
      "Done with ihdp_npci_48.csv\n",
      "Done with ihdp_npci_49.csv\n",
      "Done with ihdp_npci_5.csv\n",
      "Done with ihdp_npci_50.csv\n",
      "Done with ihdp_npci_6.csv\n",
      "Done with ihdp_npci_7.csv\n",
      "Done with ihdp_npci_8.csv\n",
      "Batch 2: Invalid loss, terminating training\n",
      "Done with ihdp_npci_9.csv\n"
     ]
    }
   ],
   "source": [
    "df_result_all = pd.DataFrame()\n",
    "\n",
    "for filename in sorted(os.listdir(ihdp_dir)):\n",
    "    df = pd.read_csv(f'{ihdp_dir}/{filename}', header=None)\n",
    "    col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ]\n",
    "\n",
    "    for i in range(1,26):\n",
    "        col.append(\"x\"+str(i))\n",
    "    df.columns = col\n",
    "\n",
    "    X = df.loc[:,'x1':]\n",
    "    treatment = df['treatment']\n",
    "    y = df['y_factual']\n",
    "    tau = df.apply(lambda d: d['y_factual'] - d['y_cfactual']\n",
    "                   if d['treatment']==1\n",
    "                   else d['y_cfactual'] - d['y_factual'], axis=1)\n",
    "\n",
    "    p_model = LogisticRegressionCV(penalty='elasticnet', solver='saga', l1_ratios=np.linspace(0,1,4),\n",
    "                                   cv=StratifiedKFold(n_splits=3, shuffle=False))\n",
    "    p_model.fit(X, treatment)\n",
    "    p = p_model.predict_proba(X)[:, 1]\n",
    "\n",
    "    s_learner = BaseSRegressor(XGBRegressor())\n",
    "    s_ate = s_learner.estimate_ate(X, treatment, y)[0]\n",
    "    s_ite = s_learner.fit_predict(X, treatment, y)\n",
    "\n",
    "    t_learner = BaseTRegressor(XGBRegressor())\n",
    "    t_ate = t_learner.estimate_ate(X, treatment, y)[0][0]\n",
    "    t_ite = t_learner.fit_predict(X, treatment, y)\n",
    "\n",
    "    x_learner = BaseXRegressor(XGBRegressor())\n",
    "    x_ate = x_learner.estimate_ate(X, p, treatment, y)[0][0]\n",
    "    x_ite = x_learner.fit_predict(X, p, treatment, y)\n",
    "\n",
    "    r_learner = BaseRRegressor(XGBRegressor())\n",
    "    r_ate = r_learner.estimate_ate(X, p, treatment, y)[0][0]\n",
    "    r_ite = r_learner.fit_predict(X, p, treatment, y)\n",
    "\n",
    "    dragonnet = train_dragon(treatment.values.reshape(-1,1),\n",
    "                                          y.values.reshape(-1,1),\n",
    "                                          X.values,\n",
    "                                          dragon='dragonnet',\n",
    "                                          targeted_regularization=True,\n",
    "                                          val_split=0.2, neurons_per_layer=100, batch_size=64, epochs=100,\n",
    "                                          verbose=False)\n",
    "\n",
    "    dragonnet_preds = dragonnet.predict(X.values)\n",
    "    dragonnet_ite = (dragonnet_preds[:,1] - dragonnet_preds[:,0]).reshape(-1,1)\n",
    "    dragonnet_ate = dragonnet_ite.mean()\n",
    "\n",
    "    mae = lambda true,pred: np.mean(np.abs(true - pred))\n",
    "\n",
    "    df_preds = pd.DataFrame([s_ite.ravel(),\n",
    "                              t_ite.ravel(),\n",
    "                              x_ite.ravel(),\n",
    "                              r_ite.ravel(),\n",
    "                              dragonnet_ite.ravel(),\n",
    "                              tau.ravel(),\n",
    "                              treatment.ravel(),\n",
    "                              y.ravel()],\n",
    "                           index=['S','T','X','R','dragonnet','tau','w','y']).T\n",
    "\n",
    "    df_cumgain = get_cumgain(df_preds)\n",
    "\n",
    "    df_result = pd.DataFrame([s_ate, t_ate, x_ate, r_ate, dragonnet_ate, tau.mean()],\n",
    "                         index=['S','T','X','R','dragonnet','actual'], columns=['ATE'])\n",
    "    df_result['MAE'] = [mae(t,p) for t,p in zip([s_ite, t_ite, x_ite, r_ite, dragonnet_ite],\n",
    "                                             [tau.values.reshape(-1,1)]*5 )\n",
    "                    ] + [None]\n",
    "    df_result['AUUC'] = auuc_score(df_preds)\n",
    "    df_result.reset_index(inplace=True)\n",
    "    df_result['file'] = filename\n",
    "    df_result_all = pd.concat((df_result_all, df_result))\n",
    "    \n",
    "    print(f'Done with {filename}')\n",
    "\n",
    "df_result_all.rename({'index':'model'}, axis=1, inplace=True)\n",
    "\n",
    "# manual adjustment\n",
    "df_result_all.loc[df_result_all.apply(lambda d: d['model']=='dragonnet' and np.isnan(d['MAE']), axis=1),\n",
    "                 'AUUC'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:20:18.393349Z",
     "start_time": "2020-01-15T00:20:18.309076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>AUUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ihdp_npci_1.csv</th>\n",
       "      <th>R</th>\n",
       "      <td>3.392378</td>\n",
       "      <td>1.379784</td>\n",
       "      <td>0.539915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>3.887754</td>\n",
       "      <td>1.108337</td>\n",
       "      <td>0.545272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>3.949531</td>\n",
       "      <td>1.087281</td>\n",
       "      <td>0.551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>4.010829</td>\n",
       "      <td>1.130968</td>\n",
       "      <td>0.543934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>4.029661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ihdp_npci_9.csv</th>\n",
       "      <th>S</th>\n",
       "      <td>10.467238</td>\n",
       "      <td>8.312217</td>\n",
       "      <td>1.147244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>10.437422</td>\n",
       "      <td>3.475345</td>\n",
       "      <td>1.166413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>9.019373</td>\n",
       "      <td>6.895362</td>\n",
       "      <td>1.145507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>10.460491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dragonnet</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ATE       MAE      AUUC\n",
       "file            model                                   \n",
       "ihdp_npci_1.csv R           3.392378  1.379784  0.539915\n",
       "                S           3.887754  1.108337  0.545272\n",
       "                T           3.949531  1.087281  0.551643\n",
       "                X           4.010829  1.130968  0.543934\n",
       "                actual      4.029661       NaN       NaN\n",
       "...                              ...       ...       ...\n",
       "ihdp_npci_9.csv S          10.467238  8.312217  1.147244\n",
       "                T          10.437422  3.475345  1.166413\n",
       "                X           9.019373  6.895362  1.145507\n",
       "                actual     10.460491       NaN       NaN\n",
       "                dragonnet        NaN       NaN       NaN\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_all.groupby(['file','model']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:18:54.415404Z",
     "start_time": "2020-01-15T00:18:54.350139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>AUUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>2.432765</td>\n",
       "      <td>0.755999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>2.599897</td>\n",
       "      <td>0.763107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>1.547712</td>\n",
       "      <td>0.777792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>2.188928</td>\n",
       "      <td>0.765631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dragonnet</th>\n",
       "      <td>1.219804</td>\n",
       "      <td>0.673524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MAE      AUUC\n",
       "model                        \n",
       "R          2.432765  0.755999\n",
       "S          2.599897  0.763107\n",
       "T          1.547712  0.777792\n",
       "X          2.188928  0.765631\n",
       "actual          NaN       NaN\n",
       "dragonnet  1.219804  0.673524"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_all.groupby('model').mean()[['MAE','AUUC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance with result from simulation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:28:00.705847Z",
     "start_time": "2020-01-14T23:28:00.647372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T23:48:10.830152Z",
     "start_time": "2020-01-14T23:48:10.722207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2460000174576988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ATE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>AUUC</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>4.417201</td>\n",
       "      <td>1.239931</td>\n",
       "      <td>0.583065</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>4.618019</td>\n",
       "      <td>1.088651</td>\n",
       "      <td>0.594821</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X</td>\n",
       "      <td>4.415116</td>\n",
       "      <td>1.181548</td>\n",
       "      <td>0.586271</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>3.898648</td>\n",
       "      <td>1.490834</td>\n",
       "      <td>0.572499</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dragonnet</td>\n",
       "      <td>4.394847</td>\n",
       "      <td>1.128743</td>\n",
       "      <td>0.591419</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actual</td>\n",
       "      <td>4.454654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ihdp_npci_43.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model       ATE       MAE      AUUC              file\n",
       "0          S  4.417201  1.239931  0.583065  ihdp_npci_43.csv\n",
       "1          T  4.618019  1.088651  0.594821  ihdp_npci_43.csv\n",
       "2          X  4.415116  1.181548  0.586271  ihdp_npci_43.csv\n",
       "3          R  3.898648  1.490834  0.572499  ihdp_npci_43.csv\n",
       "4  dragonnet  4.394847  1.128743  0.591419  ihdp_npci_43.csv\n",
       "5     actual  4.454654       NaN       NaN  ihdp_npci_43.csv"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_idx = 42\n",
    "\n",
    "with np.load(f'/Users/mike.yung/Documents/repos/dragonnet/result/ihdp/dragonnet/{file_idx}/baseline/0_replication_train.npz') as f:\n",
    "    _pred = f['q_t1'] - f['q_t0']\n",
    "    _idx = f['index']\n",
    "\n",
    "with np.load(f'/Users/mike.yung/Documents/repos/dragonnet/result/ihdp/dragonnet/{file_idx}/simulation_outputs.npz') as f:\n",
    "    _t = f['t']\n",
    "    _y = f['y']\n",
    "    _y_cf = f['y_cf']    \n",
    "\n",
    "df_sim = pd.DataFrame({'y':_y.ravel(),\n",
    "                       'y_cf': _y_cf.ravel(),\n",
    "                       't': _t.ravel(),\n",
    "})\n",
    "df_sim['tau'] = df_sim.apply(lambda d: d['y'] - d['y_cf'] if d['t']==1 else d['y_cf'] - d['y'], axis=1)    \n",
    "\n",
    "print(mae(df_sim.loc[_idx, 'tau'], _pred))\n",
    "df_result_all[df_result_all['file']==f'ihdp_npci_{file_idx+1}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalml",
   "language": "python",
   "name": "causalml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
